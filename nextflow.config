params {
    input = null

    // TO-DO, pipeline parameters
    ENABLE_DATA_HASHING = false
    ENABLE_SCRUBLET = false
    use_igvf_reference = true
    is_10x3v3 = true


    DUAL_GUIDE = false
    REFERENCE_transcriptome = 'human'
    REFERENCE_gtf_download_path = 'https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_46/gencode.v46.annotation.gtf.gz'
    REFERENCE_gtf_local_path = '/path/to/gencode_gtf.gtf.gz'

    QC_min_genes_per_cell = 500
    QC_min_cells_per_gene = 0.05
    QC_pct_mito = 20

    Multiplicity_of_infection = 'low'

    GUIDE_ASSIGNMENT_method = 'sceptre'
    GUIDE_ASSIGNMENT_capture_method = 'CROP-seq'
    GUIDE_ASSIGNMENT_cleanser_probability_threshold = 1
    GUIDE_ASSIGNMENT_SCEPTRE_probability_threshold = 'default'
    GUIDE_ASSIGNMENT_SCEPTRE_n_em_rep = 'default'

    INFERENCE_method = 'default'
    INFERENCE_target_guide_pairing_strategy = 'default'

    INFERENCE_predefined_pairs_to_test = "path/to/file.csv"
    INFERENCE_max_target_distance_bp = 1000000

    INFERENCE_SCEPTRE_side = 'both'
    INFERENCE_SCEPTRE_grna_integration_strategy = 'union'
    INFERENCE_SCEPTRE_resampling_approximation = 'skew_normal'
    INFERENCE_SCEPTRE_control_group = 'default'
    INFERENCE_SCEPTRE_resampling_mechanism = 'default'
    INFERENCE_SCEPTRE_formula_object = 'default'

    NETWORK_custom_central_nodes = 'undefined'
    NETWORK_central_nodes_num = 1

    // Dashboard parameters
    css = "assets/css"
    js = "assets/js"
    svg = "assets/svg"

    // Resource Limit
    max_cpus = 128      // TO-DO, YOU set this limit
    max_memory = 256.GB  // TO-DO, YOU set this limit

    // Container
    containers {
        base     = 'sjiang9/conda-docker:0.3'
        cleanser = 'ghcr.io/gersbachlab-bioinformatics/cleanser:1.2'
        sceptre  = 'sjiang9/sceptre-igvf:0.1'
        perturbo = 'loganblaine/perturbo'
        aria2    = 'biasofpriene/aria2c'

    }

    // TO-DO, Google Cloud specific parameters
    google_bucket = 'gs://igvf-pertub-seq-pipeline-data'
    google_project = 'igvf-pertub-seq-pipeline'
    google_region = 'us-central1'

    // Boilerplate options
    outdir                       = null
    publish_dir_mode             = 'copy'
    email                        = null
    email_on_fail                = null
    plaintext_email              = false
    monochrome_logs              = false
    hook_url                     = null

    version                      = false
    pipelines_testdata_base_path = 'https://raw.githubusercontent.com/nf-core/test-datasets/'

    // Config options
    config_profile_name        = null
    config_profile_description = null

    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_contact     = null
    config_profile_url         = null
}


// Define compute profiles
profiles {
    // Local profile
    local {
        process {
            executor = 'local'
            errorStrategy = { task.attempt <= 3 ? 'retry' : 'terminate' }
        }

        // Optional: Set work/singularity-cache directory for local runs
        workDir = './work'
        singularity.cacheDir = './singularity-cache'
    }

    // TO-DO, SLURM profile
    slurm {
        process {
            executor = 'slurm'
            queue = 'short,normal,long' // TO-DO, modify the SLURM partition
            errorStrategy = { task.attempt <= 3 ? 'retry' : 'terminate' }
        }

        executor {
            name = 'slurm'
            queueSize = 100
            pollInterval = '30 sec'
            submitRateLimit = '10 sec'
        }
        // Optional: Set work/singularity-cache directory for SLURM runs
        workDir = './work'
        singularity.cacheDir = './singularity-cache'
    }

    // Google Cloud profile
    google {

        process {
            executor = 'google-batch'
            errorStrategy = {
                if (task.exitStatus == 0) {
                    return 'ignore'
                } else if (task.exitStatus in [137, 143, 50001, 50002, 50003, 50006]) {
                    return 'retry'
                } else {
                    return 'terminate'
                }
            }
            maxRetries = 3
        }

        executor.exitReadTimeout = '10 min'

        google {
            project = params.google_project
            location = params.google_region
            batch.spot = true
            batch.maxSpotAttempts  = 5
            httpReadTimeout  = '1800 s'
            httpConnectTimeout   = '600 s'
            batch.bootDiskSize = 100.GB
        }

        // Optional: Set work/singularity-cache directory for SLURM runs
        workDir = "${params.google_bucket}/work"
        singularity.cacheDir = "${params.google_bucket}/singularity-cache"
    }
}

// Global process configuration
process {

    publishDir = [
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].tokenize('_')[0].toLowerCase()}" },
        mode: params.publish_dir_mode,
        saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
    ]

    withName: 'downloadGTF|downloadGenome|skipGenomeDownload|skipGTFDownload|anndata_concat|createGuideRef|createHashingRef|seqSpecCheck|createDashboard_HASHING|createDashboard|createDashboard_HASHING_default|createDashboard_default|CreateMuData_HASHING|CreateMuData|demultiplex|doublets_scrub|downloadReference|filter_hashing|hashing_concat|prepare_assignment|mudata_concat|inference_mudata|prepare_guide_inference|prepare_user_guide_inference|prepare_all_guide_inference|PreprocessAnnData|seqSpecParser|prepare_covariate|mergedResults|publishFiles|mergeMudata|evaluation_plot|evaluation_undefined_plot|evaluation_plot_default|evaluation_undefined_plot_default' {
        container = params.containers.base
        cpus = { Math.min(4 * task.attempt, params.max_cpus) }
        memory = { [50.GB * task.attempt, params.max_memory].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-16' : null
        }
    }

    // Higher resource processes
    withName: 'mappingGuide|mappingHashing|mappingscRNA' {
        container = params.containers.base
        cpus = { Math.min(8 * task.attempt, params.max_cpus) }
        memory = { [100.GB * task.attempt, params.max_memory].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-32' : null
        }
    }

    withName: 'guide_assignment_cleanser' {
        container = params.containers.cleanser
        cpus = { Math.min(8 * task.attempt, params.max_cpus) }
        memory = { [100.GB * task.attempt, params.max_memory].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-32' : null
        }
    }

    withName: 'guide_assignment_sceptre|inference_sceptre' {
        container = params.containers.sceptre
        // Align CPUs with downloadGTF|downloadGenome steps
        cpus = { Math.min(8 * task.attempt, params.max_cpus) }
        memory = { [200.GB * task.attempt, params.max_memory].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-64' : null
        }
    }

    withName: 'inference_perturbo|inference_perturbo_trans' {
        container = params.containers.perturbo
        // GPU processes
        cpus = { Math.min(4 * task.attempt, 48) }
        memory = { [100.GB * task.attempt, params.max_memory].min() }
        machineType = 'n1-highmem-32'
        accelerator  = [request: 1, type: 'nvidia-tesla-t4']
    }

    withName: 'downloadReference' {
        container = params.containers.aria2
        // GPU processes
        cpus = { Math.min(4 * task.attempt, 48) }
        memory = { [100.GB * task.attempt, params.max_memory].min() }
        machineType = 'n1-highmem-32'
        accelerator  = [request: 1, type: 'nvidia-tesla-t4']
    }

}



// Singularity configuration
singularity {
    enabled = true
    autoMounts = true
    runOptions = '--nv'
}

// Tower configuration
tower {
    enabled = System.getenv('TOWER_ACCESS_TOKEN') ? true : false
    accessToken = System.getenv('TOWER_ACCESS_TOKEN') ?: ''
}

// Execution reporting
trace {
    enabled = false
    file = 'pipeline_trace.txt'
    overwrite = true
}

// Additional reporting
report {
    enabled = false
    file = 'execution_report.html'
    overwrite = true
}

timeline {
    enabled = false
    file = 'timeline_report.html'
    overwrite = true
}

