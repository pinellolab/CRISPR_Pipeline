params {
    input = null

    // TO-DO, pipeline parameters
    ENABLE_DATA_HASHING = 'true'

    METADATA_sgRNA = 'gs://igvf-pertub-seq-pipeline-data/data/guide_metadata.tsv'
    METADATA_hash = 'gs://igvf-pertub-seq-pipeline-data/data/hash_metadata.tsv'

    REFERENCE_transcriptome = 'human'
    REFERENCE_gtf_download_path = 'https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_46/gencode.v46.annotation.gtf.gz'
    REFERENCE_gtf_local_path = '/path/to/gencode_gtf.gtf.gz'

    SEQUENCE_PARSING_barcode_list = 'gs://igvf-pertub-seq-pipeline-data/data/yaml_files/737K-august-2016.txt'

    QC_min_genes_per_cell = 500
    QC_min_cells_per_gene = 3
    QC_pct_mito = 20

    Multiplicity_of_infection = 'undecided'

    GUIDE_ASSIGNMENT_method = 'sceptre'
    GUIDE_ASSIGNMENT_capture_method = 'CROP-seq'
    GUIDE_ASSIGNMENT_cleanser_probability_threshold = 1

    INFERENCE_method = 'perturbo'
    INFERENCE_predefined_pairs_to_test = "path/to/file.csv"
    INFERENCE_target_guide_pairing_strategy = 'by_distance'
    INFERENCE_max_target_distance_bp = 1000000

    INFERENCE_SCEPTRE_side = 'both'
    INFERENCE_SCEPTRE_grna_integration_strategy = 'union'
    INFERENCE_SCEPTRE_resampling_approximation = 'skew_normal'
    INFERENCE_SCEPTRE_control_group = 'default'
    INFERENCE_SCEPTRE_resampling_mechanism = 'default'
    INFERENCE_SCEPTRE_formula_object = 'default'

    NETWORK_custom_central_nodes = 'undefined'
    NETWORK_central_nodes_num = 1

    // Dashboard parameters
    css = "assets/css"
    js = "assets/js"
    svg = "assets/svg"

    // Resource Limit
    max_cpus = 128      // TO-DO, YOU set this limit
    max_memory = '256.GB'  // TO-DO, YOU set this limit

    // Container
    containers {
        base     = 'sjiang9/conda-docker:0.2'
        cleanser = 'sjiang9/cleanser:0.3'
        sceptre  = 'sjiang9/sceptre-igvf:0.1'
        perturbo = 'loganblaine/perturbo:latest'
    }

    // TO-DO, Google Cloud specific parameters
    google_bucket = 'gs://igvf-pertub-seq-pipeline-data'
    google_project = 'igvf-pertub-seq-pipeline'
    google_region = 'us-central1'

    // Boilerplate options
    outdir                       = null
    publish_dir_mode             = 'copy'
    email                        = null
    email_on_fail                = null
    plaintext_email              = false
    monochrome_logs              = false
    hook_url                     = null

    version                      = false
    pipelines_testdata_base_path = 'https://raw.githubusercontent.com/nf-core/test-datasets/'

    // Config options
    config_profile_name        = null
    config_profile_description = null

    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_contact     = null
    config_profile_url         = null
}


// Define compute profiles
profiles {
    // Local profile
    local {
        process {
            executor = 'local'
            errorStrategy = { task.attempt <= 3 ? 'retry' : 'terminate' }
        }

        // Optional: Set work directory for local runs
        workDir = './work'
    }

    // TO-DO, SLURM profile
    slurm {
        process {
            executor = 'slurm'
            queue = 'short,normal,long' // TO-DO, modify the SLURM partition
            errorStrategy = { task.attempt <= 3 ? 'retry' : 'terminate' }
        }

        executor {
            name = 'slurm'
            queueSize = 100
            pollInterval = '30 sec'
            submitRateLimit = '10 sec'
        }
        // Optional: Set work directory for SLURM runs
        workDir = './work'
    }

    // Google Cloud profile
    google {
        workDir = "${params.google_bucket}/work"

        process {
            executor = 'google-batch'
            errorStrategy = {
                if (task.exitStatus == 0) {
                    return 'ignore'
                } else if (task.exitStatus in [137, 143, 50001, 50002, 50003, 50006]) {
                    return 'retry'
                } else {
                    return 'terminate'
                }
            }
            maxRetries = 3
        }

        executor.exitReadTimeout = '10 min'

        google {
            project = params.google_project
            location = params.google_region
            batch.spot = true
            batch.maxSpotAttempts  = 5
            httpReadTimeout  = '300 s'
            httpConnectTimeout   = '60 s'
            batch.bootDiskSize = 100.GB
        }
    }
}

// Global process configuration
process {

    publishDir = [
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].tokenize('_')[0].toLowerCase()}" },
        mode: params.publish_dir_mode,
        saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
    ]

    withName: 'downloadGTF|downloadGenome|skipGenomeDownload|skipGTFDownload|anndata_concat|createGuideRef|createHashingRef|seqSpecCheck|createDashboard_HASHING|createDashboard|CreateMuData_HASHING|CreateMuData|demultiplex|doublets_scrub|downloadReference|filter_hashing|hashing_concat|prepare_assignment|mudata_concat|inference_mudata|prepare_guide_inference|prepare_user_guide_inference|prepare_all_guide_inference|PreprocessAnnData|seqSpecParser|prepare_covariate|mergedResults|evaluation_plot|evaluation_undefined_plot' {
        container = params.containers.base
        cpus = { Math.min(4 * task.attempt, params.max_cpus) }
        memory = { [50.GB * task.attempt, params.max_memory as nextflow.util.MemoryUnit].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-16' : null
        }
    }

    // Higher resource processes
    withName: 'mappingGuide|mappingHashing|mappingscRNA' {
        container = params.containers.base
        cpus = { Math.min(8 * task.attempt, params.max_cpus) }
        memory = { [100.GB * task.attempt, params.max_memory as nextflow.util.MemoryUnit].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-32' : null
        }
    }

    withName: 'guide_assignment_cleanser' {
        container = params.containers.cleanser
        cpus = { Math.min(8 * task.attempt, params.max_cpus) }
        memory = { [100.GB * task.attempt, params.max_memory as nextflow.util.MemoryUnit].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-32' : null
        }
    }

    withName: 'guide_assignment_sceptre|inference_sceptre' {
        container = params.containers.sceptre
        cpus = { Math.min(8 * task.attempt, params.max_cpus) }
        memory = { [200.GB * task.attempt, params.max_memory as nextflow.util.MemoryUnit].min() }
        machineType = {
            workflow.profile == 'google' ? 'n2-highmem-64' : null
        }
    }

    withName: 'inference_perturbo' {
        container = params.containers.perturbo
        // GPU processes
        cpus = { Math.min(8 * task.attempt, params.max_cpus) }
        memory = { [100.GB * task.attempt, params.max_memory as nextflow.util.MemoryUnit].min() }
        machineType = 'n1-highmem-64'
        accelerator  = [request: 1, type: 'nvidia-tesla-t4']
    }
}

// Singularity configuration
singularity {
    enabled = true
    autoMounts = true
    runOptions = '--nv'
    cacheDir = { workflow.profile == 'google' ? "${params.google_bucket}/singularity-cache" : './singularity-cache' }
}

// Tower configuration
tower {
    enabled = "${TOWER_ACCESS_TOKEN ? true : false}"
    accessToken = "${TOWER_ACCESS_TOKEN ?: ''}"
}

// Execution reporting
trace {
    enabled = false
    file = 'pipeline_trace.txt'
    overwrite = true
}

// Additional reporting
report {
    enabled = false
    file = 'execution_report.html'
    overwrite = true
}

timeline {
    enabled = false
    file = 'timeline_report.html'
    overwrite = true
}

